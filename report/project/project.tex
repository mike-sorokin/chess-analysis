\chapter{Implementation}\label{implementationChapter}

\section{Lichess.org Puzzle Database}

\subsection{Overview}

This project requires access to various examples of chess puzzles with
pre-defined difficulties and themes. Fortunately, the \citet{lichessPuzzles}
puzzle database, which was mentioned in Section \ref{lichessPuzzlesSection},
provides approximately 3.8 million chess puzzles which have been generated from
user games played on Lichess. These puzzles are stored in FEN format, with a
reference to the game where they appeared. They also contain the solution as a
string moves, the tactics tags \citep{lichessXML}, and the puzzle rating, along
with other metadata.

An example puzzle string is shown below. This puzzle is also shown visually in
Figures \ref{puzzle1} and \ref{puzzle2}.

\begin{verbatim}
q3k1nr/1pp1nQpp/3p4/1P2p3/4P3/B1PP1b2/B5PP/5K2 b k - 0 17,
e8d7 a2e6 d7d8 f7f8,1760,80,83,72,mate mateIn2 middlegame short,
https://lichess.org/yyznGmXs/black#34,
Italian_Game Italian_Game_Classical_Variation
\end{verbatim}

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=q3k1nr/1pp1nQpp/3p4/1P2p3/4P3/B1PP1b2/B5PP/5K2 b k -
        0 17]
        \caption{\textbf{ZensAlviani -- desso2b}, lichess.org Blitz game, move
        17.}
        \label{puzzle1}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=q5nr/1ppknQpp/3p4/1P2p3/4P3/B1PP1b2/B5PP/5K2 w - - 1
        18]
        \caption{\textbf{ZensAlviani -- desso2b}, lichess.org Blitz game, move
        18.
        Checkmate is imminent with \texttt{18.Be6+ Kd8 19.Qf8\#}.}
        \label{puzzle2}
    \end{minipage}
\end{figure}

Processing these is a trivial task with one small detail: the given FEN strings
are the state of the game right before the critical blunder is played by the
opposing site. This means the puzzle, as shown to the user, is the position
after the first move has been played. Fortunately, processing this data is made
simple with the python-chess library \citep{pythonChess}.

\subsection{Data Exploration}

The lichess puzzle database has approximately 3.8 million rated and tagged
chess puzzles. Initially, they were automatically processed
\citep{lichessTagger}, but were then refined with user feedback
\citep{lichessPuzzles}. This also allowed the puzzles to obtain a rating, which
is indicative of its difficulty \citep{lichessPuzzles}.

Overall, there are 60 various puzzle themes \citep{lichessXML}. Figure
\ref{dataThemeCounts} shows the counts of each theme in all of the contained
puzzles. It should be noted that some themes are mutually exclusive (a
checkmate puzzle cannot be both \emph{mate-in-one} and \emph{mate-in-two}).

The most common puzzle themes are the most general ones -- specifically
`short', `middlegame', and `endgame'. There is a lot of variation in how
frequent the various patterns are, which is a natural consequence of the game.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{project/img/puzzle_theme_counts.png}
    \caption{Frequency of puzzle themes in the lichess.org puzzle
    database.\cite{lichessPuzzles}}
    \label{dataThemeCounts}
\end{figure}

Figure \ref{dataHistogram} shows the distribution of ratings across the chess
puzzles. It should be noted that these ratings are only appropriate within this
dataset, and cannot be compared to ratings of puzzles on other chess websites.
The puzzle ratings are quite symmetric about the mean, and this is of course a
result of the Glicko2 rating system, developed by \citet{glicko}.

When analysing the rating distribution by theme, an expected behaviour occurs.
Some chess tactics patterns are considerably simpler to spot, meaning a weaker
player is able to solve the puzzle with that theme. Therefore some puzzle
themes, \emph{back-rank mate}, for example, have lower-rated puzzles when
compared to puzzles featuring a \emph{trapped piece} or \emph{defensive
move}.\footnote{Notoriously difficult for humans, who are usually much better
at aggression than defense.\footnotemark}\footnotetext{In chess.}

Figures \ref{puzzle3} and \ref{puzzle4} show examples of some puzzles with
these themes.

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{project/img/puzzle_histogram.png}
        \caption{Distribution of Lichess puzzle ratings.}
        \label{dataHistogram}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]
            {project/img/puzzle_theme_histograms.png}
        \caption{Distribution of Lichess puzzle ratings with a specific theme.}
        \label{dataThemeHistogram}
    \end{minipage}
\end{figure}

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=6k1/5ppp/r1p5/p1n1rP2/8/2P2N1P/2P3P1/3R2K1 w - - 0
        22]
        \caption{\textbf{Kenan2345 -- gandie}, lichess.org Blitz game, move 22. 
        Black loses to \texttt{22.Rd8+}.}
        \label{puzzle3}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=2rq1rk1/7p/1n4pb/1R2Q3/pPpP1P2/P1B5/3N2PP/2R3K1 b -
        - 0 31]
        \caption{\textbf{mhabib -- Sarg0n}, lichess.org Blitz game, move 31.
        White loses his queen after \texttt{31...Re38}, as the queen has no
        safe squares to escape to.}

        \label{puzzle4}
    \end{minipage}
\end{figure}

\section{The Machine Learning Approach}\label{transformersSection}

\subsection{Introduction}

In this section, we describe, analyse, and evaluate a novel approach to the
specific problem of chess puzzle classification, inspired by the recent
unstoppable advancements in the field of natural language processing.

Earlier, we highlighted a number of papers which seek to find new ways to build
on the naive bitboard representation \citep{middleGamePatterns, chessCNN,
chess2vec} by exploring new embeddings for chess pieces and chess board
squares. All three of the publications make the crucial point that chess pieces
influence each other on the board, and this has to be taken into account,
whether it is by creating extra features to represent pins and central square
control \citep{chessCNN}, open files and attack squares
\citep{middleGamePatterns}, or the hash of the entire chess board
\cite{chess2vec}.

Continuing along the `chess board as a $N\times64$ vector' path and, given how
puzzle tactics rely on the interaction of pieces' locations and attack squares,
it seems natural to explore whether the transformer architecture, as described
in the infamous paper `Attention is All you Need' \citep{attention}, can help
extract patterns from static chess positions, which can then be used in the
downstream task of puzzle classification and difficulty rating. Figure
\ref{attentionLinks}, taken from this paper, shows how words/tokens can
influence each other in the transformer encoder. At a high level, chess pieces
and squares interact in a similar way on the chess board -- see Figure
\ref{chessPuzzleLinks} for an example.

Applying transformers to chess has been done before by
\citet{chessTransformer}, but as far as we are aware, treating individual chess
board squares as embeddings of tokens/words has not been previously explored.

\begin{figure}[H]
    \begin{minipage}{0.425\textwidth}
        \centering
        \includegraphics[width=\textwidth]{project/img/attention.png}
        \caption{Example of attention mechanism in the encoder. Taken from
        `Attention Is All You Need' \citep{attention}.}
        \label{attentionLinks}
    \end{minipage}
   \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=r3r1n1/bp6/p2p2kp/3N4/2P3n1/1PQ3Pq/P4P2/4RRK1 w - -
        0 1,
                    pgfstyle=border,markfields={d5},
                    pgfstyle=straightmove,
                    markmoves={f4-g6,f4-h3,c7-a8,c7-e8,d5-c7,d5-f4},
                    pgfstyle=color,opacity=0.5,
                    color=blue,markfields={f4,c7},
                    pgfstyle=color,opacity=0.5,
                    color=red,markfields={h3,g6,a8,e8}]
        \caption{Example of a relationship between chess pieces.}

        \label{chessPuzzleLinks}
    \end{minipage}
\end{figure}

\subsection{Data Preparation}

We formulate the problem of chess puzzle analysis as a multi-label
classification problem. Given a chess puzzle position in bitboard format,
i.e.\@ a $12\times8\times8$ binary tensor, we aim to predict a binary indicator
vector which encodes the labels of the puzzle themes. Slightly more formally,
the element $B[z, x, y]$ of bitboard $B$ is $1$ iff there is a piece $z \in
\{\texttt{p}, \texttt{P}, \texttt{n}, \texttt{N}, \texttt{b}, \texttt{B},
\texttt{r}, \texttt{R}, \texttt{q}, \texttt{Q}, \texttt{k},
\texttt{K}\}$\footnote{FEN-inspired -- white pieces are uppercase,
black pieces are lowercase.} at rank $x \in \{\texttt{1}, \texttt{2},
\texttt{3}, \texttt{4}, \texttt{5}, \texttt{6}, \texttt{7}, \texttt{8}\}$},
file $y \in \{\texttt{a}, \texttt{b}, \texttt{c}, \texttt{d}, \texttt{e},
\texttt{f}, \texttt{g}, \texttt{h}\}$.

Given a dataset with $N$ distinct puzzle labels ($N=60$ for the Lichess puzzle
database), we assign each label an index $i$ and form a binary $N$-dimensional
vector $x$ such that $x[i]=1$ iff the puzzle is labelled with that label. This
is a common technique to reduce a multi-label classification into a more
tractable problem.

To make learning easier (and to decrease implementation complexity), we
transform all chess positions to be from the perspective of White. This has
negligible additional overhead, as it requires a simple mirror and has great
benefits, as the model no longer needs to distinguish between white-to-move and
black-to-move puzzles.

\subsection{Model Architecture}

\begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{project/img/ml_diagram.png}
        \caption{High-level overview of the model architecture.}
        \label{MLDiagram}
\end{figure}


\section{The Graph-Based Approach}\label{treesSection}

\subsection{Introduction}

In this section, we propose a different novel approach to puzzle
classification, focusing on unsupervised puzzle clustering and defining a
distance function between various chess puzzles.

This method seeks to combine and build upon two approaches seen in the above
literature review: the tree-based puzzle difficulty classification
\citep{chessTrees} covered in Section \ref{chessTreesOverview} and chess
position similarity using dynamic features \citep{chessMotifs} covered in
Section \ref{chessMotifsOverview}. We hypothesise that by combining these
approaches to construct meaningful search trees with additional node labels,
defining a distance function for individual chess moves, and applying a
labelled tree edit distance function \citep{editDistTrees}, we would be able to
calculate `closeness' of chess puzzles. This could also help refine the work of
\citet{chessTrees} by finer segregating puzzles by difficulty level.

\subsection{High-Level Overview}

As explored by \citet{chessTrees}, `meaningful search trees' have predictive
possibility of a puzzle's difficulty. These trees are constructed by analysing
powerful moves that either gain, or at least do not worsen a side's position. 

By additionally labelling these trees with move information, we hope to build
upon this work. To demonstrate the intuition behind this idea, there are two
labelled search trees shown in Figures \ref{tree1}, \ref{tree2}. These are the
search trees for positions in Figures \ref{chess5}, \ref{chess6} which feature
a identical and complex tactical motif. 

In the following trees, algebratic notation of the moves is shown, along with 4
slash-delimited integers, which correspond to: pieces attacked, pieces
defended, number of attackers, number of defenders.\footnote{As the moves must
be legal, this means a king move will never have any attackers, and any
check/mate will have at least 1 piece attacked -- the enemy king.} Whilst the 2
trees do not look similar visually (their size being the main problem), the
first 3 plies are very similar. 

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{project/img/trees/1.drawio.png}
        \caption{Labelled search tree for game in \ref{chess5}}
        \label{tree1}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{project/img/trees/2.drawio.png}
        \caption{Labelled search tree for game in \ref{chess6}}
        \label{tree2}
    \end{minipage}
\end{figure}

In Figures \ref{puzzle5}, \ref{puzzle6} are two chess puzzles from the paper
`Automatic Recognition of Similar Chess Motifs' \citep{chessMotifs}. Despite
their visual difference, these both feature a rook sacrifice, and an imminent
queen checkmate helped by the powerful light-squared bishop. This similarity is
not immediately obvious, but the search trees for these puzzles is almost
identical, except for minor attacker/defender discrepancies. The trees are
shown in Figures \ref{tree3}, \ref{tree4}. These puzzles were already
successfully grouped by \citet{chessMotifs}.

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen= 4r1k1/1b3pp1/4p3/p2r4/7R/2B1Q1PP/P1P1RP1K/1q6 w - -
        0 1]
        \caption{Taken from `Automatic Recognition of Similar Chess Motifs'
        \citep{chessMotifs}. White mates in 3 (\texttt{1.Rh8+ Kxh8 2.Qh6+ Kg8
        3.Qxg7#}).}
        \label{puzzle5}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=r5k1/5pp1/8/3p3R/2q4P/PbB2P2/1P1Q2P1/K7 w q - 0 1]
            \caption{Also taken from `Automatic Recognition of Similar Chess
            Motifs' \citep{chessMotifs}. White mates in 3 with the same moves
            as the puzzle on the left.}
        \label{puzzle6}
    \end{minipage}
\end{figure}

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{project/img/trees/3.drawio.png}
        \caption{Labelled search tree for game in Figure \ref{puzzle5}.}
        \label{tree3}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{project/img/trees/4.drawio.png}
        \caption{Labelled search tree for game in Figure \ref{puzzle6}.}
        \label{tree4}
    \end{minipage}
\end{figure}

\subsection{Meaningful Tree Generation}\label{treeGenSection}

Similar to the work of \citet{chessTrees}, Stockfish (depth=20) was used to
generate meaningful trees of a maximum depth of 5 ply. Each level of the tree
has a maximum of 4 possible moves that are within 100 centipawns (arbitrarily
chosen) of the best move.

\citet{chessTrees} writes: ``[A high branching factor] means that the position
is already so strong that it no longer matters what move the player chooses
because almost everything wins.''; the tree search is terminated if the best 4
moves for the losing side are within 100 centipawns. While this differs from
the quote above, it causes trees to terminate when the puzzle is completed (any
move for the losing side is equally bad), as opposed to one move before (any
move for the winning side is equally good). Finally, a checkmate naturally
indicates that the puzzle is solved. 

This analysis is continued until either every branch of the puzzle is
exhausted, whether because it has solved the puzzle, or ran out of the maximum
depth of 5.

Whilst generating the tree nodes, each move is annotated with a list of
attributes describing the properties of these move. The exhaustive list of the
attributes we consider is as follows:

\begin{itemize}
    \item Colour of the piece
    \item Piece name (queen, rook, etc.\@)
    \item Depth of the node
    \item File, rank, diagonals (2 types: parallel to \texttt{a1-h8} or
        \texttt{a8-h1}) of the source square
    \item File, rank, diagonals of the target square
    \item Chebyshev distance (number of king moves) between source and target
        squares     
    \item Which piece is captured (if any)
    \item Delivers check or not
    \item Delivers mate or not
    \item Number of enemy pieces attacked after the move
    \item Number of friendly pieces defended after the move
    \item Number of enemy attackers after the move
    \item Number of friendly defenders after the move
\end{itemize}

In total, we generated 3.7 million game trees which took about 10000 hours of
CPU time. This was done with the help of the Department of Computing's HTCondor
cluster.

\subsection{What Makes Chess Moves Similar?}

Given the list in Section \ref{treeGenSection}, we define a distance function
between two given lists of attributes. All of the parameters are completely
arbitrary and were devised by an intermediate chess player. In Table
\ref{distanceTable}, the `penalties' for each discrepancy is listed. The final
distance between two nodes is the sum of all of the per-item distances.

The depth of the node affects the final scaling for the distance. The reasoning
behind this is that an initial move is much more important when comparing two
puzzles, but later moves are less important. This is also because there is
usually a lot of differences later in the move tree, and harshly penalising led
to worse results, from early experiments. The depth multipliers are: $4, 1,
0.5, 0.25, 0.1, 0.05$ for depths $0$ through to $5$, respectively.

\begin{table}[H]
  \centering
  \begin{tabular}{lrl}
      Condition & Penalty & Note \\
      \hline
      Different colour & $\infty$ & Implementation detail \\
      &&\\
      Pieces are queen/rook & $25$ & Heavy pieces are used similarly \\
      Pieces are queen/bishop& $50$ & Both can attack diagonally \\
      Pieces are different and not QR/QB& $100$ & \\
      &&\\
      Differing source rank/file/diagonal & $3$ each & \\
      Differing target rank/file/diagonal & $3$ each & \\
      Chebyshev distances $d_1, d_2$ & $|d_1-d_2|$ & Move distance is often
      not important \\
      &&\\
      Capture and non-capture & $50$ & \\
      Capture of different pieces & $10$ & \\
      Checking and non-checking & $25$ & \\
      Mate and non-mate & $50$ & \\
      &&\\
      Number of enemies attacked, $n_1, n_2$ & $3|n_1-n_2|$ & \\
      Number of allies defended, $n_1, n_2$ & $2|n_1-n_2|$ & \\
      Number of attackers, $n_1, n_2$ & $3|n_1-n_2|$ & \\
      Number of defenders, $n_1, n_2$ & $2|n_1-n_2|$ & \\
  \end{tabular}
  \caption{Breakdown of the node distance function for meaningful move trees}
  \label{distanceTable}
\end{table}

This distance function defines a distance between nodes of move trees. Together
with the unordered labelled tree edit distance algorithm \citep{editDistTrees},
we can now compare any two chess puzzles. As an example, Table
\ref{distanceComparisons} shows the distances between the puzzles in Figures
\ref{chess1}, \ref{chess2} (back-rank mate in 1), \ref{puzzle5}, \ref{puzzle6}
(rook sacrifice, mate in 3) and \ref{chess5}, \ref{chess6} (complex mating
sequence).

\begin{table}[H]
  \centering
  \begin{tabular}{r|cccccc}
    Figure &
    \ref{chess1}&\ref{chess2}&\ref{puzzle5}&\ref{puzzle6}&\ref{chess5}&\ref{chess6}
    \\
    \hline
    \ref{chess1} & $0$ & $232$ & $978.5$ & $982.5$ & $1422$ & $1714$ \\ 
    \ref{chess2} & $232$ & $0$ & $1086.5$ & $1082.5$ & $1278$ & $1586$ \\
    \ref{puzzle5} & $978.5$ & $1086.5$ & $0$ & $46.5$ & $789$ & $1033.15$ \\
    \ref{puzzle6} & $982.5$ & $1082.5$ & $46.5$ & $0$ & $795$ & $1035.15$ \\
    \ref{chess5} & $1422$ & $1278$ & $789$ & $795$ & $0$ & $417$ \\
    \ref{chess6} & $1714$ & $1586$ & $1033.15$ & $1035.15$ & $417$ & $0$ \\
  \end{tabular}
  \caption{Distance matrix for a few chess puzzles.}
  \label{distanceComparisons}
\end{table}

\subsection{Finding Similar Positions Given a Puzzle}

Generating the distance matrix in Table \ref{distanceComparisons} is
prohibitively expensive, as it scales quadratically with the number of
positions -- calculating this for the whole Lichess database is difficult. By
extracting one row, however, we can rank puzzles in order of similarity to a
given puzzle.

For a simple back-rank mate in 1 puzzle, this is incredibly effective. Given
the puzzle in Figure \ref{chess1}, we are able to find positions like the ones
in Figures \ref{m11} and \ref{m22}. These positions are arguably more complex
as there are more pieces on the board, making it harder to find the winning
move.

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen= 6k1/pr4pR/2p2pP1/2Pp4/5N2/P1r2P2/3RP3/3K4 b - - 1
        28]
        \caption{Distance $40$ to Figure \ref{chess1}. Solution:
        \texttt{1...Rb1\#}}
        \label{m11}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=1r4k1/6p1/p1R1p2p/8/P6P/3R4/2P2rP1/3K4 b - - 0 30]
        \caption{Distance $0$ to Figure \ref{chess1}. Solution:
        \texttt{1...Rb1\#}}
        \label{m22}
    \end{minipage}
\end{figure}

With a more complex position, such as the mate in two in Figure \ref{chess5},
this method returns the positions in Figures \ref{mag1} and \ref{mag2}. These
do not feature exactly the same tactic, but they are nonetheless similar,
featuring a rook sacrifice on \texttt{h3} and different mating squares
depending on White's response.

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=2k3r1/p1p4p/8/pP1QR3/P2P3P/2P3r1/5RPK/3q4 b - - 2 30]
        \caption{Distance $255$ to Figure \ref{chess5}. Solution:
        \texttt{1...Rh3+ (2.Kxh3 Qh1\#) (2.gxh3 Qg1\#)}}
        \label{mag1}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=6rk/pR6/2p4p/8/4PP2/P2P2r1/P2Q1RPK/q7 b - - 4 35]
        \caption{Distance $259$ to Figure \ref{chess5}. Solution identical to
        puzzle on the left.}
        \label{mag2}
    \end{minipage}
\end{figure}

\subsection{Unsupervised Clustering on Puzzle Distances}

To take this further, a distance matrix was constructed for a random sample of
10000 puzzles from the Lichess puzzle database. A few labelled puzzles were
added to help with analysis of the results. A selection of unsupervised
clustering algorithms were ran on this matrix to identify clusters of puzzles
which are all similar to each other. Many of the standard clustering algorithms
were not available due to the nature of the problem -- there is no obvious
vector space representing the search trees, ruling out algorithms like K-means
\citep{lloyd1982least} or Mean Shift \citep{fukunaga1975estimation}.

We attempted Agglomerative Clustering (average, single, complete)
\citep{szekely2005hierarchical}, DBSCAN \citep{dbscan}, and HDBSCAN
\citep{hdbscan} on this subset of the database. The results are shown in Tables
\ref{tabAC}, \ref{tabDBSCAN} and \ref{tabHDBSCAN}.

\begin{table}[H]
  \centering
  \begin{adjustbox}{width=\textwidth}
  \begin{tabular}{lr|rccccrrrrrrr}
    \multicolumn{2}{l}{Parameters}&&\multicolumn{4}{c}{Puzzle is in a cluster}
    &&
    \multicolumn{6}{c}{Cluster size statistics} \\

    Linkage&Distance threshold&Number of clusters&\rotatebox{90}{Backrank M1} &
    \rotatebox{90}{Knight fork} & \rotatebox{90}{Greek gift} &
    \rotatebox{90}{Rook sac M3} & Outlier \% & \rotatebox{90}{Mean} &
    \rotatebox{90}{Min} & \rotatebox{90}{Q1} & \rotatebox{90}{Median} &
    \rotatebox{90}{Q3} & \rotatebox{90}{Max} \\

    \hline
    average&100&16973&Y&Y&Y&Y&0&1.18&1&1&1&1&177\\
    average&250&13725&Y&Y&Y&Y&0&1.46&1&1&1&1&1000\\
    average&500&8468&Y&Y&Y&Y&0&2.36&1&1&1&1&1863\\
    complete&100&17224&Y&Y&Y&Y&0&1.16&1&1&1&1&85\\
    complete&250&13983&Y&Y&Y&Y&0&1.43&1&1&1&1&611\\
    complete&500&9063&Y&Y&Y&Y&0&2.21&1&1&1&1&1000\\
    single&100&16732&Y&Y&Y&Y&0&1.2&1&1&1&1&611\\
    single&250&13389&Y&Y&Y&Y&0&1.49&1&1&1&1&2652\\
    single&500&7196&Y&Y&Y&Y&0&2.78&1&1&1&1&10057\\

  \end{tabular}
  \end{adjustbox}
  \caption{Results of Agglomerative Clustering}
  \label{tabAC}
\end{table}

\begin{table}[H]
  \centering
  \begin{adjustbox}{width=\textwidth}
  \begin{tabular}{rr|rccccrrrrrrr}
    \multicolumn{2}{l}{Parameters}&&\multicolumn{4}{c}{Puzzle is in a cluster}
    &&
    \multicolumn{6}{c}{Cluster size statistics} \\

    Epsilon&Minimum samples&Number of clusters&\rotatebox{90}{Backrank M1} &
    \rotatebox{90}{Knight fork} & \rotatebox{90}{Greek gift} &
    \rotatebox{90}{Rook sac M3} & Outlier \% & \rotatebox{90}{Mean} &
    \rotatebox{90}{Min} & \rotatebox{90}{Q1} & \rotatebox{90}{Median} &
    \rotatebox{90}{Q3} & \rotatebox{90}{Max} \\

    \hline
  50&3&51& & & & &92.52&29.35&3&8&13&27&375\\
  50&5&46& & & & &92.61&32.15&5&9&15&29&375\\
  50&7&44& & & & &92.67&33.32&7&10&15&29&375\\
  100&3&52&Y& & &Y&83.26&64.4&3&9&15&35&1000\\
  100&5&48&Y& & &Y&83.33&69.48&5&11&19&41&1000\\
  100&7&43&Y& & &Y&83.49&76.79&7&11&21&45&1000\\
  250&3&38&Y& &Y&Y&66.71&175.26&4&10&21&79&2652\\
  250&5&36&Y& &Y&Y&66.75&184.78&5&12&25&88&2652\\
  250&7&36&Y& &Y&Y&66.79&184.56&7&13&25&88&2652\\
  500&3&6&Y&Y&Y&Y&35.88&2137.67&7&86&346&1630&10068\\
  500&5&6&Y&Y&Y&Y&35.88&2137.67&7&86&346&1630&10068\\
  500&7&6&Y&Y&Y&Y&35.89&2137.33&7&86&346&1630&10067\\

  \end{tabular}
  \end{adjustbox}
  \caption{Results of DBSCAN}
  \label{tabDBSCAN}
\end{table}

\begin{table}[H]
  \centering
  \begin{adjustbox}{width=\textwidth}
  \begin{tabular}{rr|rccccrrrrrrr}
    \multicolumn{2}{l}{Parameters}&&\multicolumn{4}{c}{Puzzle is in a cluster}
    &&
    \multicolumn{6}{c}{Cluster size statistics} \\

    Cluster selection $\epsilon$&Min cluster size&Number of
    clusters&\rotatebox{90}{Backrank M1} &
    \rotatebox{90}{Knight fork} & \rotatebox{90}{Greek gift} &
    \rotatebox{90}{Rook sac M3} & Outlier \% & \rotatebox{90}{Mean} &
    \rotatebox{90}{Min} & \rotatebox{90}{Q1} & \rotatebox{90}{Median} &
    \rotatebox{90}{Q3} & \rotatebox{90}{Max} \\

    \hline
    0&3&1176&Y&Y&Y&Y&46.36&9.12&3&3&6&9&303\\
    0&5&735& &Y& &Y&50.76&13.4&5&6&8&12&351\\
    0&7&522& &Y& &Y&54.33&17.5&7&8&10&15&345\\
    25&3&1229&Y&Y& &Y&45.37&8.89&3&4&5&9&327\\
    25&5&707& &Y& &Y&49.43&14.31&5&6&8&13&404\\
    25&7&524&Y&Y& &Y&55.00&17.18&7&8&10&16&339\\
    50&3&1221&Y&Y& &Y&42.99&9.34&3&3&5&9&367\\
    50&5&700& &Y& &Y&49.48&14.44&5&6&8&12&373\\
    50&7&468& &Y& &Y&53.28&19.97&7&8&10&16&375\\
    100&3&1127&Y&Y&Y&Y&40.35&10.59&3&3&5&8&1000\\
    100&5&627&Y&Y& &Y&45.91&17.26&5&6&8&11&1000\\
    100&7&420&Y&Y& &Y&52.08&22.82&7&8&10&14&1000\\
    /
  \end{tabular}
  \end{adjustbox}
  \caption{Results of HDBSCAN}
  \label{tabHDBSCAN}
\end{table}

From these tables, it is easy to identify the methods that really struggle to
create meaningful clusters out of the given chess puzzles. Namely, all variants
of Agglomerative Clustering produced results with at least 7000 clusters,
which, for a subset of 20000 puzzles, is too many. It is not obvious what an
appropriate cluster count result is; the Lichess database has approximately 60
unique themes, which gives a very rough target. However, the Lichess database
themes are not mutually exclusive, unlike the cluster membership produced by
these algorithms. 

A different heuristic used as a sign that a method is inappropriate is whether
it assigns a cluster to 4 simple chess puzzles. These are shown below. These
puzzles were selected as their tactical pattern is relatively common,
especially Figures \ref{chess11} and \ref{chess12}. This means that a
clustering method that fails to assign these a cluster (labelling them an
`outlier') is unlikely to be effective overall.

\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=6k1/5ppp/8/8/8/8/r4PPP/1R4K1 w - - 0 1]
        \caption{Backrank M1: \texttt{1.Rb8\#}}
        \label{chess11}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=8/1N6/1K6/4k1p1/2P1Pp1p/4n2P/3R2P1/8 b - - 0 49]
        \caption{Knight forks rook and king with \texttt{1...Nxc4+}}
        \label{chess12}
    \end{minipage}
\end{figure}


\begin{figure}[H]
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen=
        r1bq1rk1/pp2nppp/1bn1p3/1N1pP3/1P6/P2B1N2/2P2PPP/R1BQK2R w KQ - 3 11]
        \caption{Greek gift sacrifice: \texttt{1.Bxh7+ Kxh7 2.Ng5+}}
        \label{chess13}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.475\textwidth}
        \centering
        \chessboard[setfen= 4r1k1/1b3pp1/4p3/p2r4/7R/2B1Q1PP/P1P1RP1K/1q6 w - -
        0 1]
        \caption{Rook sacrificed for mate in three: \texttt{1.Rh8+ Kxh8 2.Qh6+
        Kg8 3.Qxg7\#}}
        \label{chess14}
    \end{minipage}
\end{figure}

This allowed some parameter combinations of DBSCAN to be disqualified,
specifically the lower epsilon ones. Epsilon is the distance at which points
are considered to be in one neighbourhood \citep{dbscan}, and setting this too
low means similar puzzles are not given the same cluster. The distance matrix
in Table \ref{distanceComparisons} shows that puzzles which are similar to a
human can have a distance of 417, and this is by no means an upper limit.


